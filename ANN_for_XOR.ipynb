{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN for XOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Artificial Neural Network - Multi-layered perceptron</h1>\n",
        "<h2>XOR function example</h2>"
      ],
      "metadata": {
        "id": "U3k2xCkPxHDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5C-W2xI2wlQy"
      },
      "outputs": [],
      "source": [
        "#Artificial Neural Network Example\n",
        "# XOR function\n",
        "import math;\n",
        "import numpy as np#for array/matrix calculations\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning);#ignore the warning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Sigmoid Function</h4>\n",
        "$$f(x)=\\frac{1}{1+e^{-\\alpha x}}$$<br/>\n",
        "$$f'(x)=\\alpha f(x)(1-f(x))$$"
      ],
      "metadata": {
        "id": "B-l-i8G5w0tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aconst=2;\n",
        "def sigmoid(x):\n",
        "    return 1/(1+math.exp(-aconst*(x)));\n",
        "def dsigmoid(x):\n",
        "    sigx=sigmoid(x);    \n",
        "    return aconst*sigx*(1-sigx);"
      ],
      "metadata": {
        "id": "WUl50YOwxC8l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error: $$e_{k}=d_{k}-y_{k}$$ where $d_k$ is the desired output, and $y_k$ is the output of the network<br/>\n",
        "$$total\\space energy\\space ξ=\\frac{1}{2}\\sum_{k}e_{k}^{2}(n)$$\n",
        "$$\\sum_{k}e_{k}^{2}(n)=e_{k}\\cdot e_{k}$$<br/>\n",
        "as $$a\\cdot b=\\sum_{i=1}^{n}=a_1b_1+a_2b_2+...+a_nb_n$$<br/>\n"
      ],
      "metadata": {
        "id": "9QHPxQmxxggp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sq_error(output,desired):#square error\n",
        "    dif = output.ravel() - desired.ravel() #find the difference of each value in the array\n",
        "    return np.dot( dif, dif )#dot product\n",
        "def totalerr_energy(output,desired):\n",
        "    return sq_error(output,desired)/2;\n"
      ],
      "metadata": {
        "id": "rSPh9DYPw1OS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Feed forward</h3>\n",
        "$v_k=\\sum_{k=0}^{m}w_{km}x_k$<br/>\n",
        "$w_k0=b_k$ which is the bias\n",
        "$y_k=φ(v_k)$<br/>\n",
        "where $φ(v_k)=\\frac{1}{1+exp^{-\\alpha x}}$ the sigmoid function"
      ],
      "metadata": {
        "id": "wJRnS_eC02ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feedforward(inp,weights):\n",
        "    prev_layer=inp;\n",
        "    prev_layer=np.append(prev_layer,1);#add the bias\n",
        "    curlayers=[prev_layer];\n",
        "    bcurlayers=[prev_layer];#current neuron states (before activation)\n",
        "    nolayers=len(weights);\n",
        "    for l in range(nolayers):\n",
        "        no_neurons=weights[l].shape[0]\n",
        "        thislayer=np.zeros(no_neurons);\n",
        "        bthislayer=np.zeros(no_neurons);#before activation\n",
        "        for i in range(no_neurons):\n",
        "            bthislayer[i]=np.dot(prev_layer,weights[l][i]);#(before activation)\n",
        "            thislayer[i]=sigmoid(bthislayer[i]);\n",
        "        prev_layer=thislayer;\n",
        "        curlayers.append(np.array(thislayer));\n",
        "        bcurlayers.append(np.array(bthislayer));#add to the layers (before activation)\n",
        "    return curlayers,bcurlayers;"
      ],
      "metadata": {
        "id": "dICj0GqwxetP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Back Propagation</h3>\n",
        "$Δw_{ji}=-\\eta \\frac{\\partial ξ}{\\partial w_{ji}}=-\\eta \\{-e_jφ'_j(v_j)y_i\\}$<br/>\n",
        "$Δw_{ji}=\\etaδ_jy_i$ <br/>\n",
        "where $\\delta_j=e_jφ'_j(v_j)$<br/>\n",
        "$φ'_j(v_j)=\\alpha y_j[1-y_j]$<br/>\n",
        "if neuron j is an output neuron $\\delta_j=\\alpha[d_j-y_j]y_j[1-y_j]$<br/>\n",
        "if neuron j is a hidden neuron $\\delta_j=\\alpha y_j[1-y_j]\\sum_k{\\delta_kw_{kj}}$\n"
      ],
      "metadata": {
        "id": "hZRUyrka2a4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(desired,curlayers,bcurlayers,weights,learning_rate):\n",
        "    newweights=np.copy(weights);\n",
        "    nolayers=len(weights);\n",
        "    output=curlayers[nolayers];\n",
        "    delta=aconst*(desired-output)*output*(1-output);#the output neuron\n",
        "    for l in reversed(range(nolayers)):#propagate backwards\n",
        "        pdelta=np.array([delta],dtype=object);#convert it to a 2D array for transpose    \n",
        "        newweights[l]=weights[l]+ learning_rate*curlayers[l]*pdelta.T;\n",
        "        delta=aconst*curlayers[l]*(1-curlayers[l])*(np.dot(delta,weights[l]));        \n",
        "    return newweights;"
      ],
      "metadata": {
        "id": "h0_tnNuD0xQO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>XOR Example</h3>\n",
        "\n",
        "| Input 1|Input 2      | Output |\n",
        "| --- |--- | --- |\n",
        "| 0 | 0 | 0|\n",
        "| 0 | 1 | 1|\n",
        "| 1 | 0 | 1|\n",
        "| 1 | 1 | 0|"
      ],
      "metadata": {
        "id": "IjUyv7ko6BOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('XOR example')\n",
        "print('------------------------------------')\n",
        "no_input=2;#  2 inputs \n",
        "no_output=1;# 1 output\n",
        "training_data=np.array([[0,0],[0,1],[1,0],[1,1]]);#xor\n",
        "desired_outputs=np.array([0,1,1,0]);#xor output\n",
        "learning_rate=0.9;\n",
        "Max_no_epochs=5000;#maximum no of epochs for training\n",
        "target_err=0.0001;#targeted output average error\n",
        "#-----------------------------------------------------\n",
        "#only 1 hidden layer\n",
        "neurons=[no_input+1,3,no_output];#i.e. no of neurons in each layer 1 input layer, 1 hidden layer + 1 output layer\n",
        "weights=[];\n",
        "nolayers=len(neurons)-1;\n",
        "for i in range(nolayers):\n",
        "    layer1=neurons[i];\n",
        "    layer2=neurons[i+1];\n",
        "    curweightlayer=np.random.rand(layer2,layer1);\n",
        "    weights.append(curweightlayer);\n",
        "#-----------------------------------------------------\n",
        "no_trainingdata=training_data.shape[0];\n",
        "#training the NN\n",
        "average_err=1;#average error\n",
        "epoch=0;#no epochs\n",
        "while average_err>target_err and epoch<Max_no_epochs:\n",
        "    for j in range(no_trainingdata):\n",
        "        inp=training_data[j];\n",
        "        desired=np.array(desired_outputs[j]);\n",
        "        curlayers,bcurlayers=feedforward(inp,weights);#feed forward\n",
        "        output=curlayers[nolayers];#output of the artificial neural network\n",
        "        weights=backpropagation(desired,curlayers,bcurlayers,weights,learning_rate);\n",
        "        average_err+=totalerr_energy(output,desired);#averaged error \n",
        "    average_err/=no_trainingdata;\n",
        "    epoch+=1;    \n",
        "print('no epochs:',epoch,'averaged err:',average_err);\n",
        "#show inference results\n",
        "print('------------------------------------')\n",
        "print('Inference results')\n",
        "for j in range(no_trainingdata):\n",
        "    inp=training_data[j];\n",
        "    desired=np.array(desired_outputs[j]);\n",
        "    feedforwardresult,bcurlayers=feedforward(inp,weights);\n",
        "    output=feedforwardresult[nolayers];\n",
        "    print('input:',inp,'desired:',desired,'NN output:',output);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMgzkvLm2SiO",
        "outputId": "d369cc44-3f20-4b0a-f184-6cc9b398a6a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR example\n",
            "------------------------------------\n",
            "no epochs: 2472 averaged err: 9.996571968328928e-05\n",
            "------------------------------------\n",
            "Inference results\n",
            "input: [0 0] desired: 0 NN output: [0.00852342]\n",
            "input: [0 1] desired: 1 NN output: [0.98589797]\n",
            "input: [1 0] desired: 1 NN output: [0.98859425]\n",
            "input: [1 1] desired: 0 NN output: [0.01404396]\n"
          ]
        }
      ]
    }
  ]
}